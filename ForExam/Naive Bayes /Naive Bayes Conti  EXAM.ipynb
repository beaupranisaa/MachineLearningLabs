{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Conti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('diabetes.csv',delimiter = ',')\n",
    "\n",
    "# print(data)\n",
    "# print(type(data))\n",
    "# Extract headers and data\n",
    "X = data.iloc[:,0:7]\n",
    "y = data.iloc[:,8]\n",
    "# print(X)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  768\n",
      "Number of features:  7\n"
     ]
    }
   ],
   "source": [
    "# check number of samples\n",
    "m = X.shape[0]\n",
    "print(\"Number of samples: \", m)\n",
    "# check number of features\n",
    "n = X.shape[1]\n",
    "print(\"Number of features: \", n)\n",
    "\n",
    "# check number of y\n",
    "assert m == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for train data:\n",
      "------------------------\n",
      " Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Pandas \n",
    "#Convert to DataFrame to check for missing data\n",
    "df = pd.DataFrame(X)\n",
    "print('Missing values for train data:\\n------------------------\\n', df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...   0.     33.6     0.627]\n",
      " [  1.     85.     66.    ...   0.     26.6     0.351]\n",
      " [  8.    183.     64.    ...   0.     23.3     0.672]\n",
      " ...\n",
      " [  5.    121.     72.    ... 112.     26.2     0.245]\n",
      " [  1.    126.     60.    ...   0.     30.1     0.349]\n",
      " [  1.     93.     70.    ...   0.     30.4     0.315]]\n"
     ]
    }
   ],
   "source": [
    "X = df.values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize/Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63994726  0.84832379  0.14964075 ... -0.69289057  0.20401277\n",
      "   0.46849198]\n",
      " [-0.84488505 -1.12339636 -0.16054575 ... -0.69289057 -0.68442195\n",
      "  -0.36506078]\n",
      " [ 1.23388019  1.94372388 -0.26394125 ... -0.69289057 -1.10325546\n",
      "   0.60439732]\n",
      " ...\n",
      " [ 0.3429808   0.00330087  0.14964075 ...  0.27959377 -0.73518964\n",
      "  -0.68519336]\n",
      " [-0.84488505  0.1597866  -0.47073225 ... -0.69289057 -0.24020459\n",
      "  -0.37110101]\n",
      " [-0.84488505 -0.8730192   0.04624525 ... -0.69289057 -0.20212881\n",
      "  -0.47378505]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of X_train, y_train\n",
      "(460, 7) (460,)\n",
      "shapes of X_test, y_test\n",
      "(308, 7) (308,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "m, n = X.shape\n",
    "idx = np.arange(0, m)\n",
    "random.shuffle(idx)\n",
    "percent_train = 0.6\n",
    "m_train = int(m * percent_train)\n",
    "train_idx = idx[0:m_train]\n",
    "test_idx = idx[m_train:]\n",
    "X_train = X[train_idx,:];\n",
    "X_test = X[test_idx,:];\n",
    "\n",
    "y_train = y[train_idx];\n",
    "y_test = y[test_idx];\n",
    "\n",
    "# double check the shapes\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "# assert len(X_train)  == len(y_train)\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "# assert len(X_test) == len(y_test)\n",
    "\n",
    "print('shapes of X_train, y_train')\n",
    "print(X_train.shape,y_train.shape)\n",
    "print('shapes of X_test, y_test')\n",
    "print(X_test.shape,y_test.shape)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of each features by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_byclass(X,y):\n",
    "    labels = np.unique(y)\n",
    "    X_class = {}\n",
    "    y_class = {}\n",
    "    for label in labels:\n",
    "        X_class[label] = X[y==label]\n",
    "        y_class[label] = y[y==label]\n",
    "    return X_class,y_class\n",
    "        \n",
    "#     X0 = X[y==0,:]\n",
    "#     X1 = X[y==1,:]\n",
    "#     y0 = y[y==0]\n",
    "#     y1 = y[y==1]\n",
    "#     return X0,X1,y0,y1\n",
    "# labels = np.unique(y_train)\n",
    "\n",
    "# X = (X-np.mean(X, axis = 0))/np.std(X, axis = 0)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1])\n",
      "(307, 7)\n",
      "(153, 7)\n",
      "dict_keys([0, 1])\n",
      "dict_keys([0, 1])\n",
      "(193, 7)\n",
      "(115, 7)\n",
      "dict_keys([0, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train_byclass,y_train_byclass= get_data_byclass(X_train,y_train)\n",
    "print(X_train_byclass.keys())\n",
    "print(X_train_byclass[0].shape)\n",
    "print(X_train_byclass[1].shape)\n",
    "print(y_train_byclass.keys())\n",
    "\n",
    "X_test_byclass,y_test_byclass= get_data_byclass(X_test,y_test)\n",
    "print(X_test_byclass.keys())\n",
    "print(X_test_byclass[0].shape)\n",
    "print(X_test_byclass[1].shape)\n",
    "print(y_test_byclass.keys())\n",
    "\n",
    "\n",
    "# print(X_train_byclass.items())\n",
    "\n",
    "# X0_train,X1_train,y0_train,y1_train = get_data_byclass(X_train,y_train)\n",
    "# X0_test,X1_test,y0_test,y1_test = get_data_byclass(X_test,y_test)\n",
    "# print('shapes of X_train, y_train')\n",
    "# print(X0_train.shape,y0_train.shape)\n",
    "# print(X1_train.shape,y1_train.shape)\n",
    "# print('shapes of X_test, y_test')\n",
    "# print(X0_test.shape,y0_test.shape)\n",
    "# print(X1_test.shape,y1_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Mean and std of each class\n",
      "{0: [(-0.1890438100407975, 0.9033326170665503), (-0.3362782532574676, 0.8275804036898107), (0.02805842225426604, 0.8592729145502395), (-0.03855481347210192, 0.914064656765675), (-0.08432421538909939, 0.9042602418746346), (-0.18790724363413805, 0.9861818265977425), (-0.17640665419812773, 0.9076840916092841)], 1: [(0.2672834638042525, 1.1160791238356824), (0.5813775550727414, 1.0271841530484265), (0.0097527234982741, 1.2108609605780802), (0.14264355967463607, 1.0961145955481977), (0.22522635736847216, 1.2064485375695868), (0.48912482774756155, 0.900496120292233), (0.31069571132124324, 1.2543234621418713)]}\n",
      "==============================\n",
      "Number of std and mean in a class\n",
      "7\n",
      "7\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def get_gaussian_params(X_byclass):\n",
    "    parameters = [(np.mean(attribute),np.std(attribute)) for attribute in zip(*X_byclass)]\n",
    "#     print(parameters)\n",
    "######### why -1\n",
    "#     del parameters[-1]\n",
    "    return parameters\n",
    "                \n",
    "def get_params(X_byclass):\n",
    "    parameters ={}\n",
    "    for key,values in X_byclass.items():\n",
    "        parameters[key] = get_gaussian_params(values)\n",
    "    return parameters\n",
    "parameters = get_params(X_train_byclass)\n",
    "print('='*30)\n",
    "print('Mean and std of each class')\n",
    "print(parameters)\n",
    "print('='*30)\n",
    "print('Number of std and mean in a class')\n",
    "print(len(parameters[0]))\n",
    "print(len(parameters[1]))\n",
    "print(type(parameters[0]))\n",
    "# X0_mean,X0_std = get_mean_std(X_train_byclass,y_train_byclass)  \n",
    "# X1_mean,X1_std = get_mean_std(X1_train)\n",
    "# print(\"=\"*30)\n",
    "# print('shapes of mean X_train')\n",
    "# print(X0_mean.shape,X0_std.shape)\n",
    "# print(\"=\"*30)\n",
    "# print('shapes of mean X_test')\n",
    "# print(X1_mean.shape,X1_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6673913043478261, 1: 0.33260869565217394}\n"
     ]
    }
   ],
   "source": [
    "def get_prior(X_byclass,X):\n",
    "    priors= {}\n",
    "    num = X.shape[0]\n",
    "    for key,values in X_byclass.items():\n",
    "        priors[key] = len(X_byclass[key])/num\n",
    "    return priors\n",
    "priors = get_prior(X_train_byclass,X_train)\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n",
      "460\n",
      "7\n",
      "308\n",
      "308\n"
     ]
    }
   ],
   "source": [
    "def get_gaussian_pdf(X,params):\n",
    "    gaussian_pdf = {}\n",
    "    parameters={}\n",
    "    gaussian_pdf={}\n",
    "    exponent={}\n",
    "    for key, values in params.items():#,params.items():\n",
    "        # parameters[key][0] = mean, parameters[key][1] = std\n",
    "        parameters[key] = [params for params in zip(*params[key])]\n",
    "        exponent[key] = np.exp(-(np.power(X-parameters[key][0],2)/(2*np.power(parameters[key][1],2))))\n",
    "        gaussian_pdf[key] =(1/(np.sqrt(2*np.pi)*np.array(parameters[key][1]))*exponent[key])\n",
    "    return gaussian_pdf\n",
    "\n",
    "likelihood_train = get_gaussian_pdf(X_train,parameters)\n",
    "#likelihood of x belonging to each class [0 = key]\n",
    "print(len(likelihood_train[0]))\n",
    "print(len(likelihood_train[1]))\n",
    "print(len(likelihood_train[0][0])) #same number of features\n",
    "\n",
    "assert len(likelihood_train[0]) == (X_train.shape[0])\n",
    "assert len(likelihood_train[0][0]) == (X_train.shape[1])\n",
    "assert len(likelihood_train[1]) == (X_train.shape[0])\n",
    "assert len(likelihood_train[1][0]) == (X_train.shape[1])\n",
    "\n",
    "likelihood_test = get_gaussian_pdf(X_test,parameters)\n",
    "print(len(likelihood_test[0]))\n",
    "print(len(likelihood_test[1]))\n",
    "\n",
    "assert len(likelihood_test[0]) == (X_test.shape[0])\n",
    "assert len(likelihood_test[0][0]) == (X_test.shape[1])\n",
    "assert len(likelihood_test[1]) == (X_test.shape[0])\n",
    "assert len(likelihood_test[1][0]) == (X_test.shape[1])\n",
    "\n",
    "# likelihood1_train = get_gaussian_pdf(X_train,X1_mean,X1_std)\n",
    "# print(\"=\"*30)\n",
    "# print('shapes of pop X_train by feature')\n",
    "# print(likelihood0_train.shape)\n",
    "# print(likelihood1_train.shape)\n",
    "# print(\"=\"*30)\n",
    "# print('shapes of pop X_test by feature')\n",
    "# likelihood0_test = get_gaussian_pdf(X_test,X0_mean,X0_std)\n",
    "# likelihood1_test = get_gaussian_pdf(X_test,X1_mean,X1_std)\n",
    "# print(likelihood0_test.shape)\n",
    "# print(likelihood1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate total likelihood by np.prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460,)\n",
      "(308,)\n"
     ]
    }
   ],
   "source": [
    "def total_likelihood(likelihood):\n",
    "    tot_likelihood={}\n",
    "    for key,values in likelihood.items():\n",
    "        tot_likelihood[key] = np.prod(likelihood[key],axis = 1)\n",
    "    return tot_likelihood\n",
    "\n",
    "total_likelihood_train = total_likelihood(likelihood_train)\n",
    "print(total_likelihood_train[0].shape)\n",
    "total_likelihood_test = total_likelihood(likelihood_test)\n",
    "print(total_likelihood_test[0].shape)\n",
    "# total_likelihood0_train = np.prod(likelihood0_train,axis=1)\n",
    "# total_likelihood1_train = np.prod(likelihood1_train,axis=1)\n",
    "# total_likelihood0_test = np.prod(likelihood0_test,axis=1)\n",
    "# total_likelihood1_test = np.prod(likelihood1_test,axis=1)\n",
    "\n",
    "# print('shapes of total_likelihood X_train by feature')\n",
    "# print(total_likelihood0_train.shape)\n",
    "# print(total_likelihood1_train.shape)\n",
    "# print('shapes of total_likelihood X_test by feature')\n",
    "# print(total_likelihood0_test.shape)\n",
    "# print(total_likelihood1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(prior,total_likelihood):\n",
    "    posterior = {}\n",
    "    for key,values in prior.items():\n",
    "        posterior[key] = prior[key]*total_likelihood[key]\n",
    "    return posterior\n",
    "\n",
    "posterior_train = posterior(priors,total_likelihood_train)\n",
    "# print(posterior_train)\n",
    "posterior_test = posterior(priors,total_likelihood_test)\n",
    "# print(posterior_test)\n",
    "\n",
    "# posterior0_train = prior0_train*total_likelihood0_train\n",
    "# posterior1_train = prior1_train*total_likelihood1_train\n",
    "\n",
    "# print(posterior0_train.shape)\n",
    "# print(posterior1_train.shape)\n",
    "\n",
    "# posterior0_test = prior0_train*total_likelihood0_test\n",
    "# posterior1_test = prior1_train*total_likelihood1_test\n",
    "\n",
    "# print(posterior0_train.shape)\n",
    "# print(posterior1_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "460\n",
      "[0, 1]\n",
      "308\n",
      "yhat_train 460\n",
      "y_train 460\n",
      "yhat_test 308\n",
      "y_test 308\n",
      "yhat_train 308\n",
      "y_train 308\n",
      "accuracy of data train:  0.8021739130434783\n",
      "accuracy of data test:  0.711038961038961\n"
     ]
    }
   ],
   "source": [
    "def predict(posterior):\n",
    "#     predict = []\n",
    "    class_names = [key for key in posterior.keys()]\n",
    "    print(class_names)\n",
    "    \n",
    "    sample_length = len(posterior[class_names[0]])\n",
    "    print(sample_length)\n",
    "    yhat = []\n",
    "    for i_col in range(sample_length): \n",
    "        column_vector = [posterior[class_names][i_col] for class_names in posterior.keys()]\n",
    "#         print(column_vector)\n",
    "        yhat.append(np.argmax(column_vector)) \n",
    "    return yhat\n",
    "\n",
    "# yhat = predict(posterior_train)\n",
    "\n",
    "# print(yhat)\n",
    "def get_acc(yhat,y):\n",
    "    return(yhat == y).sum()/len(y)\n",
    "\n",
    "yhat_train = predict(posterior_train)\n",
    "yhat_test = predict(posterior_test)\n",
    "acc_train = get_acc(yhat_train,y_train)\n",
    "print('yhat_train',len(yhat_train))\n",
    "print('y_train',len(y_train))\n",
    "print('yhat_test',len(yhat_test))\n",
    "print('y_test',len(y_test))\n",
    "acc_test = get_acc(yhat_test,y_test)\n",
    "print('yhat_train',len(yhat_test))\n",
    "print('y_train',len(y_test))\n",
    "print(\"accuracy of data train: \",acc_train)\n",
    "print(\"accuracy of data test: \",acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
