{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Midterm, Jan Semester, 2018\n",
    "\n",
    "In this exam, you will demonstrate your understanding of the material from the lectures, tutorials, and problem sets.\n",
    "\n",
    "For each question, insert your answer directly in this sheet. When complete, export the sheet as a PDF and upload to Gradescope.\n",
    "\n",
    "Note that you have **2.5 hours** to do the exam. Also note that there are some short answer questions that you may be able to answer faster than the coding questions. You might consider answering those questions first to get as much credit as possible!\n",
    "\n",
    "## Question 1 (20 points)\n",
    "\n",
    "Consider the data ($\\mathtt{X}, \\mathbf{y}$) given in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (100, 2)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X1 = np.matrix([[70.4611978, 6.77435737], [26.63557899, 6.18519845], [21.21435842, 5.98482521],\n",
    "      [49.46520438, 6.46685477], [36.31867059, 6.26767026], [65.40450545, 6.69973324],\n",
    "      [47.63604002, 6.52991946], [51.12650291, 6.55278139], [16.19718639, 5.8701804],\n",
    "      [41.09647679, 6.39265021], [48.52977517, 6.54874167], [33.2783272, 6.24645442],\n",
    "      [54.2416494, 6.68772955], [63.87981696, 6.64426231], [49.74926534, 6.54019839],\n",
    "      [45.50085081, 6.40530107], [31.80572899, 6.33114329], [25.88027769, 6.00191626],\n",
    "      [25.34847504, 6.07445523], [59.5509754, 6.67139653], [50.69674158, 6.51872281],\n",
    "      [54.11728722, 6.58716206], [58.22172538, 6.58217774], [38.82480513, 6.43235051],\n",
    "      [54.62361945, 6.62107478], [42.24368621, 6.43349846], [44.91058546, 6.40702283],\n",
    "      [62.72139429, 6.81082283], [77.55458346, 6.86015373], [49.07536097, 6.58151526],\n",
    "      [51.48292856, 6.62113585], [57.37090719, 6.65400127], [48.48641553, 6.54340401],\n",
    "      [21.24715108, 6.07259954], [37.64146721, 6.46820336], [12.35289436, 5.4695928],\n",
    "      [37.65875476, 6.18370352], [49.85008383, 6.60947486], [66.13648137, 6.79896653],\n",
    "      [27.29008652, 6.15868866], [82.89679414, 6.86219115], [60.28610161, 6.77246816],\n",
    "      [45.99452861, 6.40409124], [77.29411953, 6.88564085], [49.24729059, 6.39129918],\n",
    "      [52.19238458, 6.52793378], [55.55244532, 6.5922497], [38.28876143, 6.35421521],\n",
    "      [41.28903755, 6.33314064], [73.83202683, 6.85274489], [62.84426032, 6.63317405],\n",
    "      [27.66679337, 6.0765891], [64.90528747, 6.7277243], [62.75897971, 6.74867287],\n",
    "      [57.47911597, 6.56964198], [32.54225548, 6.14425762], [44.7087849, 6.55684065],\n",
    "      [30.22868535, 6.17664755], [66.43902044, 6.66354862], [57.50647725, 6.63295779],\n",
    "      [56.23274763, 6.65483072], [71.62377075, 6.8249259], [37.21929751, 6.45896618],\n",
    "      [30.33685416, 6.29108668], [53.72586113, 6.55558498], [58.92009067, 6.58914418],\n",
    "      [60.36917635, 6.73713645], [46.46087002, 6.61086064], [54.97919255, 6.48830287],\n",
    "      [60.08999745, 6.63018137], [29.23503961, 6.06804535], [45.18879885, 6.44043758],\n",
    "      [67.91432786, 6.8105173], [46.5800853, 6.50060039], [56.70569052, 6.65565127],\n",
    "      [40.68951533, 6.41478636], [48.67956085, 6.48811567], [41.59182624, 6.38699182],\n",
    "      [39.95740486, 6.33546435], [44.94880975, 6.46206514], [64.78053936, 6.74188874],\n",
    "      [57.93695294, 6.73064008], [55.49704023, 6.64231398], [39.57510111, 6.29139288],\n",
    "      [33.95225046, 6.33743394], [77.23246962, 6.79966126], [56.49647686, 6.66597049],\n",
    "      [72.05710124, 6.83097927], [51.36582347, 6.63984591], [36.23540347, 6.26819074],\n",
    "      [51.33172918, 6.55170989], [65.9107458, 6.7412432], [45.92145099, 6.55785946],\n",
    "      [48.73393011, 6.5700271], [43.19824007, 6.5765512], [32.51187411, 6.17277242],\n",
    "      [66.52125325, 6.7549236], [71.77667409, 6.77447514], [27.54687135, 6.07712865],\n",
    "      [70.29209858, 6.82371897]])\n",
    "\n",
    "X2 = np.matrix([[103.48734726, 7.06665128], [45.95181945, 6.92463529], [62.51311459, 7.29929464],\n",
    "      [34.75905558, 6.82590246], [61.42150233, 7.14207452], [20.92995779, 6.18926827],\n",
    "      [48.88757058, 7.10046058], [47.00567217, 6.87392491], [66.03960746, 7.21300884],\n",
    "      [41.00765303, 6.88260887], [53.39454458, 7.12002753], [59.05801699, 7.07708207],\n",
    "      [25.84457253, 6.52661965], [20.64948341, 6.4810278], [63.28046094, 7.18001038],\n",
    "      [66.29002442, 7.24725685], [49.26589866, 7.02704851], [59.53968788, 7.12513223],\n",
    "      [48.46665858, 6.97610637], [34.51909729, 6.85422354], [61.16606292, 7.1611797],\n",
    "      [65.62870788, 7.25370585], [57.43965533, 7.12551572], [51.4256259, 7.12109028],\n",
    "      [78.45648704, 7.38957843], [70.23973965, 7.28014297], [61.12178687, 7.14687961],\n",
    "      [75.55803406, 7.2645782], [44.9666415, 7.00364604], [43.94509452, 6.94630876],\n",
    "      [44.98195858, 6.94771427], [44.07909292, 6.84250384], [33.27404217, 6.76884994],\n",
    "      [66.83707899, 7.26223859], [34.99475166, 6.75074986], [59.51675598, 7.18130986],\n",
    "      [37.03437849, 6.87742508], [62.14584595, 7.21712651], [51.37422401, 7.1478843],\n",
    "      [25.75396602, 6.83643475], [66.18768985, 7.28574587], [50.46927715, 7.0901681],\n",
    "      [66.08232926, 7.28108743], [16.81537222, 6.44176855], [38.49515228, 6.85670726],\n",
    "      [44.87889506, 6.89762361], [51.72803212, 7.15768698], [26.41099035, 6.69220322],\n",
    "      [67.40763472, 7.25475514], [60.26711966, 7.13606818], [41.26604269, 6.82072533],\n",
    "      [36.25102952, 6.81241658], [90.34415059, 7.10789215], [49.9112951, 7.04364433],\n",
    "      [37.60574769, 6.75709643], [47.69027385, 7.15224795], [70.7126762, 7.37139046],\n",
    "      [31.38034068, 6.57171353], [45.43488612, 6.97156664], [29.83557583, 6.77016354],\n",
    "      [53.58242995, 7.14264146], [40.28103375, 6.88596508], [69.76687507, 7.29225697],\n",
    "      [40.72428579, 6.90370374], [38.35168955, 6.72388286], [88.77752009, 7.30440221],\n",
    "      [52.71910503, 7.10525341], [78.13634099, 7.43246583], [55.28469075, 7.15527197],\n",
    "      [26.12154, 6.77911307], [57.9174037, 7.16031425], [59.96888213, 7.04359248],\n",
    "      [28.979886, 6.69711096], [54.10548377, 7.08093707], [46.24087958, 7.03464403],\n",
    "      [46.02151582, 6.98139406], [32.74868227, 6.69473258], [45.70424283, 6.94792668],\n",
    "      [25.85436229, 6.58336042], [77.98270261, 7.41044107], [54.65190235, 7.11080335],\n",
    "      [60.44627103, 7.07123203], [68.58296094, 7.33179762], [42.80337975, 6.87396778],\n",
    "      [31.35673666, 6.66603545], [19.04585207, 6.62207371], [48.79436125, 7.01009406],\n",
    "      [45.44124128, 7.08039785], [41.97937064, 6.854478], [53.39688062, 7.02525752],\n",
    "      [66.0637938, 7.258192], [55.09943464, 7.1307132], [65.22295533, 7.28208667],\n",
    "      [48.25983281, 6.93393588], [19.00711267, 6.33112045], [39.14998323, 6.99193013],\n",
    "      [75.51283715, 7.34232193], [20.07554717, 6.65314899], [40.64087416, 6.81927983],\n",
    "      [68.19628122, 7.3153336]])\n",
    "\n",
    "X = np.concatenate([X1, X2],0);\n",
    "y = np.concatenate([-np.matrix(np.ones([100,1])),np.matrix(np.ones([100,1]))]);\n",
    "# y = np.ravel(y)\n",
    "print(X1.shape,X2.shape)\n",
    "print(y.shape)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Q1 continued) **Do the following:**\n",
    "\n",
    "1. **In the cell below, make a scatter plot of the data for class 1 and class 2 in different colors.**\n",
    "\n",
    "2. **Answer the question, are the data linearly separable?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12107f190>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X1[:,0],X1[:,1],'or',label = \"X1\")\n",
    "plt.plot(X2[:,0],X2[:,1],'ob',label = \"X2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (20 points)\n",
    "\n",
    "**Do the following:**\n",
    "\n",
    "1. **Build a logistic regression model for the data ($\\mathtt{X},\\mathbf{y}$). Give the optimal parameter vector $\\mathbf{\\theta}$ below:**\n",
    "\n",
    "2. **Plot the data again, along with the decision boundary $\\mathbf{\\theta}^\\top \\mathbf{x} = 0$.**\n",
    "\n",
    "3. **What is the accuracy of this model on its training set?** (Note: in this problem there is no need to create separate training and test sets. Just train and test on the full data set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 2) (20, 2)\n",
      "(80, 2) (20, 2)\n",
      "(160,)\n",
      "shapes of X_train, y_train with DUMMY added\n",
      "(160, 3) (160,)\n",
      "shapes of X_test, y_test with DUMMY added\n",
      "(40, 3) (40,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X1_train = X1[0:80,:]\n",
    "X1_test = X1[80:,:]\n",
    "X2_train = X2[0:80,:]\n",
    "X2_test = X2[80:,:]\n",
    "\n",
    "print(X1_train.shape,X1_test.shape)\n",
    "print(X2_train.shape,X2_test.shape)\n",
    "\n",
    "X_train = np.concatenate((X1_train, X2_train), 0)\n",
    "y_train = np.concatenate((np.zeros((80,1)), np.ones((80,1))), 0).ravel()\n",
    "print(y_train.shape)\n",
    "# print(y_train)\n",
    "X_test = np.concatenate((X1_test, X2_test), 0)\n",
    "y_test = np.concatenate((np.zeros((20,1)), np.ones((20,1))), 0).ravel()\n",
    "# print(X_test.shape,y_test.shape)\n",
    "\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train = np.concatenate((intercept, X_train), axis=1)  #add intercept\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test = np.concatenate((intercept, X_test), axis=1)  #add intercept\n",
    "\n",
    "print('shapes of X_train, y_train with DUMMY added')\n",
    "print(X_train.shape,y_train.shape)\n",
    "print('shapes of X_test, y_test with DUMMY added')\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):   \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def get_yhat(X, theta):\n",
    "    print(X.shape,theta.shape)\n",
    "    bs = X@theta\n",
    "    print('bs',bs.shape)\n",
    "    return sigmoid(X @ theta)\n",
    "\n",
    "#loss = cost\n",
    "def get_loss(X,y,theta):\n",
    "    yhat = get_yhat(X,theta)\n",
    "    print(yhat.shape)\n",
    "    loss_new = -(np.sum(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))) / y.shape[0]\n",
    "#     print(loss_new.shape)\n",
    "    return loss_new\n",
    "\n",
    "#for early stopping\n",
    "def delta_loss(loss_new, loss_old, tol):\n",
    "    return np.abs(loss_new - loss_old) < tol\n",
    "\n",
    "# for theta updating\n",
    "# error = h_theta(X,theta) - y\n",
    "def gradient(X,y,theta):\n",
    "    grad = X.T @ (get_yhat(X,theta)-y)#/y.shape[0] \n",
    "    return grad\n",
    "\n",
    "def gradient_descent(X_train,y_train,X_test,y_test,theta_initial,alpha,max_iter):\n",
    "    theta = theta_initial\n",
    "    tol = 0.001    \n",
    "    loss_history_train = []\n",
    "    loss_history_test = []\n",
    "    loss_old_train = np.inf\n",
    "    iter_stop = 0  \n",
    "    for i in range(max_iter):\n",
    "        # calculate costs\n",
    "        loss_new_train = get_loss(X_train,y_train,theta)\n",
    "        loss_test = get_loss(X_test,y_test,theta)        \n",
    "#         print(loss_new)\n",
    "        \n",
    "        # early stopping?\n",
    "        if delta_loss(loss_new_train, loss_old_train,tol):\n",
    "            diff = np.abs(loss_new_train - loss_old_train)\n",
    "#             print(diff)\n",
    "            iter_stop = i\n",
    "            break\n",
    "        loss_old_train = loss_new_train\n",
    "#         print(loss_old.shape)\n",
    "        \n",
    "#         if i%500 == 0:\n",
    "        print(\"cost iter\",i,':',loss_old_train)\n",
    "        loss_history_train.append(loss_old_train)\n",
    "        loss_history_test.append(loss_test)\n",
    "        \n",
    "        \n",
    "        # cal grad to update theta\n",
    "        grad = gradient(X_train,y_train,theta)\n",
    "#         print(grad)\n",
    "        \n",
    "        # update theta\n",
    "        theta = theta - alpha* grad\n",
    "#         print('theta',theta)\n",
    "        \n",
    "    return loss_history_train,loss_history_test, theta, iter_stop,diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Shape of theta:  (3,)\n",
      "==============================\n",
      "Initial theta:  [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "theta_initial = np.zeros(X_train.shape[1])\n",
    "# theta_initial = theta_initial.reshape(-1,1)\n",
    "# check shape of theta\n",
    "print(\"=\"*30)\n",
    "print(\"Shape of theta: \", theta_initial.shape)\n",
    "\n",
    "# initial theta\n",
    "print(\"=\"*30)\n",
    "print(\"Initial theta: \", theta_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 3) (3,)\n",
      "bs (1, 160)\n",
      "(1, 160)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (160,) and (1,160) not aligned: 160 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-97cf46438926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malpha\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcost_history_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_history_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_initial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-685e4400cf80>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(X_train, y_train, X_test, y_test, theta_initial, alpha, max_iter)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# calculate costs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss_new_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#         print(loss_new)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-685e4400cf80>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(X, y, theta)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_yhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#     print(loss_new.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__imul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (160,) and (1,160) not aligned: 160 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "alpha  = 0.05\n",
    "max_iter = 10000\n",
    "cost_history_train,cost_history_test,theta, iter_stop,diff = gradient_descent(X_train,y_train,X_test,y_test,theta_initial,alpha = alpha ,max_iter = max_iter)\n",
    "print(iter_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points)\n",
    "\n",
    "Now suppose that we'd like to train a SVM to classify these data, but also suppose that you don't know how to modify the SVM optimization to handle data that are not linearly separable (I promised that wouldn't be on the midterm, didn't I?).\n",
    "\n",
    "Then your goal is to come up with a feature mapping $\\mathbf{\\phi}(\\mathbf{x})$ that will transform the data so that they are linearly separable.\n",
    "\n",
    "**Do the following:**\n",
    "\n",
    "1. **Explain in general what kind of transformation we should use.**\n",
    "\n",
    "2. **Experiment to find a mapping that transforms the data to another 2-dimensional feature space until you have one that works. In the cell below, add the code for the transformation and code to plot the transformed data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your mapping function here:\n",
    "\n",
    "def phi_q3(X):\n",
    "    # Transform X\n",
    "    x1_new = X[:,0]  # x1_new should be some function of x1 and x2\n",
    "    x2_new = X[:,1]  # x2_new should be some function of x1 and x2\n",
    "    return np.concatenate((x1_new,x2_new),1)\n",
    "\n",
    "# Place code to plot the data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Next we use the cvxopt library to train a SVM on the data transformed according to your answer in Question 3.\n",
    "\n",
    "**Do the following:**\n",
    "\n",
    "1. **Place your code to convert $\\mathtt{X},\\mathbf{y}$ to the direct QP problem (minimizing $\\|\\mathbf{w}\\|^2$) below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform inputs to a QP problem\n",
    "\n",
    "XX = phi_q3(X)\n",
    "Q = ...\n",
    "c = ...\n",
    "A = ...\n",
    "b = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **What are the optimal $\\mathbf{w}$ and $b$ in the feature space? Write your answer here.**\n",
    "\n",
    "3) **Plot the transformed data with the decision boundary. Add code below.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to plot transformed data and the SVM decision boundary here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Another way to transform the data to a space where they are linearly separable would have been using a kernel.\n",
    "\n",
    "**Do the following.**\n",
    "\n",
    "1. **Explain how the RBF/Gaussian kernel would solve the problem.**\n",
    "\n",
    "2. **In the cell below, show how the dual QP optimization with the linear kernel fails.**\n",
    "\n",
    "3. **After that, show how the dual QP optimization with the RBF/Gaussian kernel succeeds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for dual QP with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for dual QP with RBF/Gaussian kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
